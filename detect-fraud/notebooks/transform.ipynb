{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f485cae",
   "metadata": {},
   "source": [
    "# Data Transform\n",
    "\n",
    "In this notebook, we will ask you a series of questions to evaluate your findings from your EDA. Based on your response & justification, we will ask you to also apply a subsequent data transformation. \n",
    "\n",
    "If you state that you will not apply any data transformations for this step, you must **justify** as to why your dataset/machine-learning does not require the mentioned data preprocessing step.\n",
    "\n",
    "The bonus step is completely optional, but if you provide a sufficient feature engineering step in this project we will add `1000` points to your Kahoot leaderboard score.\n",
    "\n",
    "You will write out this transformed dataframe as a `.csv` file to your `data/` folder.\n",
    "\n",
    "**Note**: Again, note that this dataset is quite large. If you find that some data operations take too long to complete on your machine, simply use the `sample()` method to transform a subset of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90a38922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62cb65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "transactions = pd.read_csv(\"../data/bank_transactions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dff7129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-predictive columns\n",
    "transactions = transactions.drop(columns=['nameOrig', 'nameDest', 'isFlaggedFraud'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c988008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column names:\n",
      "Index(['type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest',\n",
      "       'newbalanceDest', 'isFraud'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns after dropping non-predictive ones:\n",
      "            type      amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0        PAYMENT      983.09       36730.24        35747.15            0.00   \n",
      "1        PAYMENT    55215.25       99414.00        44198.75            0.00   \n",
      "2        CASH_IN   220986.01     7773074.97      7994060.98       924031.48   \n",
      "3       TRANSFER  2357394.75           0.00            0.00      4202580.45   \n",
      "4       CASH_OUT    67990.14           0.00            0.00       625317.04   \n",
      "...          ...         ...            ...             ...             ...   \n",
      "999995   PAYMENT    13606.07      114122.11       100516.04            0.00   \n",
      "999996   PAYMENT     9139.61           0.00            0.00            0.00   \n",
      "999997  CASH_OUT   153650.41       50677.00            0.00            0.00   \n",
      "999998  CASH_OUT   163810.52           0.00            0.00       357850.15   \n",
      "999999  CASH_OUT    51379.41       45503.43            0.00       202760.18   \n",
      "\n",
      "        newbalanceDest  isFraud  \n",
      "0                 0.00        0  \n",
      "1                 0.00        0  \n",
      "2            703045.48        0  \n",
      "3           6559975.19        0  \n",
      "4            693307.19        0  \n",
      "...                ...      ...  \n",
      "999995            0.00        0  \n",
      "999996            0.00        0  \n",
      "999997       380368.36        0  \n",
      "999998       521660.67        0  \n",
      "999999       254139.59        0  \n",
      "\n",
      "[1000000 rows x 7 columns]\n",
      "\n",
      "Shape after drop: (1000000, 7)\n"
     ]
    }
   ],
   "source": [
    "# Check column names\n",
    "print(\"\\nColumn names:\")\n",
    "print(transactions.columns)\n",
    "\n",
    "# Drop non-predictive columns (like account names and naive flag)\n",
    "non_predictive_cols = ['nameOrig', 'nameDest', 'isFlaggedFraud']\n",
    "\n",
    "# List of potentially non-predictive columns\n",
    "non_predictive_cols = ['nameOrig', 'nameDest', 'isFlaggedFraud']\n",
    "\n",
    "# Only drop the columns that exist in the DataFrame\n",
    "cols_to_drop = [col for col in non_predictive_cols if col in transactions.columns]\n",
    "transactions = transactions.drop(columns=cols_to_drop)\n",
    "\n",
    "# Confirm drop\n",
    "print(\"\\nColumns after dropping non-predictive ones:\")\n",
    "print(transactions)\n",
    "\n",
    "# Confirm data shape\n",
    "print(\"\\nShape after drop:\", transactions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7098680",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'type_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Encode transaction type\u001b[39;00m\n\u001b[0;32m      2\u001b[0m encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 3\u001b[0m transactions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtype_encoder\u001b[49m\u001b[38;5;241m.\u001b[39mfit_transform(transactions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'type_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Encode transaction type\n",
    "encoder = LabelEncoder()\n",
    "transactions['type'] = type_encoder.fit_transform(transactions['type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec51ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engineered features\n",
    "transactions['errorOrig'] = transactions['oldbalanceOrg'] - transactions['newbalanceOrig'] - transactions['amount']\n",
    "transactions['errorDest'] = transactions['newbalanceDest'] - transactions['oldbalanceDest'] - transactions['amount']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1df240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Dataset Preview:\n",
      "   type      amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0     3      983.09       36730.24        35747.15            0.00   \n",
      "1     3    55215.25       99414.00        44198.75            0.00   \n",
      "2     0   220986.01     7773074.97      7994060.98       924031.48   \n",
      "3     4  2357394.75           0.00            0.00      4202580.45   \n",
      "4     1    67990.14           0.00            0.00       625317.04   \n",
      "\n",
      "   newbalanceDest  isFraud     errorOrig  errorDest  \n",
      "0            0.00        0 -3.524292e-12    -983.09  \n",
      "1            0.00        0  0.000000e+00  -55215.25  \n",
      "2       703045.48        0 -4.419720e+05 -441972.01  \n",
      "3      6559975.19        0 -2.357395e+06      -0.01  \n",
      "4       693307.19        0 -6.799014e+04       0.01  \n",
      "\n",
      "Shape after transformation: (1000000, 9)\n"
     ]
    }
   ],
   "source": [
    "# Confirm changes\n",
    "print(\"\\nTransformed Dataset Preview:\")\n",
    "print(transactions.head())\n",
    "print(\"\\nShape after transformation:\", transactions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f5eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Balance (isFraud):\n",
      "isFraud\n",
      "0    998703\n",
      "1      1297\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for class imbalance\n",
    "print(\"\\nClass Balance (isFraud):\")\n",
    "print(transactions['isFraud'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360ca62",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "Does your model contain any missing values or \"non-predictive\" columns? If so, which adjustments should you take to ensure that your model has good predictive capabilities? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    " There are **no missing values** in any of the columns, however there are **non-predictive columns** that should be removed to improve model generalization:\n",
    "'nameOrig' and 'nameDest' are account identifiers, which do not contain meaningful patterns generalizable to new data. Including them could lead to overfitting.\n",
    "'isFlaggedFraud' is a naive flag based on a fixed threshold and is not helpful as a predictor since it's already derived from the 'amount' column and performs poorly in flagging actual fraud.\n",
    "\n",
    "To improve predictive capabilities, we can drop these columns. The cleaned dataset now only includes relevant numerical features and the target variable `isFraud`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301be5ef",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "Do certain transaction types consistently differ in amount or fraud likelihood? If so, how might you transform the type column to make this pattern usable by a machine learning model? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    "Yes, certain transaction types (like TRANSFER and CASH_OUT) are more strongly associated with fraudulent behavior. Meanwhile, types like PAYMENT, DEBIT, and CASH_IN are rarely or never fraudulent.\n",
    "\n",
    "To make this pattern usable by a machine learning model, we should encode the type column into numerical values. A LabelEncoder is appropriate if we are using tree-based models like Random Forest or XGBoost. For linear models like logistic regression, we might instead use one-hot encoding to avoid introducing unintended ordinal relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952403f",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "After exploring your data, you may have noticed that fraudulent transactions are rare compared to non-fraudulent ones. What challenges might this pose when training a machine learning model? What strategies could you use to ensure your model learns meaningful patterns from the minority class? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    "Fraudulent transactions make up less than 1% of the dataset, creating a severe class imbalance. If left unaddressed, a machine learning model may learn to always predict \"not fraud\" (class 0), achieving high accuracy but zero recall on fraudulent cases.\n",
    "\n",
    "To overcome this, we can apply techniques like:\n",
    "\n",
    "Resampling, such as:\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "Random undersampling the majority class\n",
    "\n",
    "Using class weights, which penalize misclassifying minority class examples more\n",
    "\n",
    "Evaluating with metrics like F1 score, precision, and recall, not just accuracy\n",
    "\n",
    "These ensure the model learns meaningful fraud-detection patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17737e9e",
   "metadata": {},
   "source": [
    "## Bonus (optional)\n",
    "\n",
    "Are there interaction effects between variables (e.g., fraud and high amount and transaction type) that aren't captured directly in the dataset? Would it be helpful to manually engineer any new features that reflect these interactions? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    "Answer Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48b7af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cbfb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out newly transformed dataset to your folder\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
