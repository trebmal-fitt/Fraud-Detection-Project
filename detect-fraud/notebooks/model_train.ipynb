{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5bd66ee",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "In this notebook, we will ask you a series of questions regarding model selection. Based on your responses, we will ask you to create the ML models that you've chosen. \n",
    "\n",
    "The bonus step is completely optional, but if you provide a sufficient third machine learning model in this project, we will add `1000` points to your Kahoot leaderboard score.\n",
    "\n",
    "**Note**: Use the dataset that you've created in your previous data transformation step (not the original model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b90a0",
   "metadata": {},
   "source": [
    "## Questions\n",
    "Is this a classification or regression task?  \n",
    "\n",
    "Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017bfb9f",
   "metadata": {},
   "source": [
    "Are you predicting for multiple classes or binary classes?  \n",
    "\n",
    "Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd9378",
   "metadata": {},
   "source": [
    "Given these observations, which 2 (or possibly 3) machine learning models will you choose?  \n",
    "\n",
    "Random Forest (for interpretability + robustness), Logistic Regression (baseline), and XGBoost (high performance with imbalance handling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c408b67",
   "metadata": {},
   "source": [
    "## First Model\n",
    "\n",
    "Using the first model that you've chosen, implement the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fab3d0",
   "metadata": {},
   "source": [
    "### 1) Create a train-test split\n",
    "\n",
    "Use your cleaned and transformed dataset to divide your features and labels into training and testing sets. Make sure youâ€™re only using numeric or properly encoded features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0c646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc52235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare transformed data\n",
    "transactions = pd.read_csv(\"../data/bank_transactions.csv\")\n",
    "transactions = transactions.drop(columns=['nameOrig', 'nameDest', 'isFlaggedFraud'])\n",
    "transactions['type'] = LabelEncoder().fit_transform(transactions['type'])\n",
    "transactions['errorOrig'] = transactions['oldbalanceOrg'] - transactions['newbalanceOrig'] - transactions['amount']\n",
    "transactions['errorDest'] = transactions['newbalanceDest'] - transactions['oldbalanceDest'] - transactions['amount']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328fc146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features & Target\n",
    "X = transactions.drop(columns=['isFraud'])\n",
    "y = transactions['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124aa25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ab26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c97f67",
   "metadata": {},
   "source": [
    "### 2) Search for best hyperparameters\n",
    "Use tools like GridSearchCV, RandomizedSearchCV, or model-specific tuning functions to find the best hyperparameters for your first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8fc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5],\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "search_rfc = RandomizedSearchCV(\n",
    "    rfc, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=5, \n",
    "    scoring='recall', \n",
    "    cv=3, \n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search_rfc.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30eee3",
   "metadata": {},
   "source": [
    "### 3) Train your model\n",
    "Select the model with best hyperparameters and generate predictions on your test set. Evaluate your models accuracy, precision, recall, and sensitivity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ed831",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Best model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[1;32m----> 4\u001b[0m best_rfc \u001b[38;5;241m=\u001b[39m \u001b[43msearch_rfc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\n\u001b[0;32m      5\u001b[0m y_pred_rfc \u001b[38;5;241m=\u001b[39m best_rfc\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRandom Forest Performance:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "# Best model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_rfc))\n",
    "print(classification_report(y_test, y_pred_rfc, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db128d64",
   "metadata": {},
   "source": [
    "## Second Model\n",
    "\n",
    "Create a second machine learning object and rerun steps (2) & (3) on this model. Compare accuracy metrics between these two models. Which handles the class imbalance more effectively?\n",
    "\n",
    "Create as many code-blocks as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732baab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create and fit model\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear')\n",
    "lr.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20991bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train model\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(\"\\n Logistic Regression Results:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66c411",
   "metadata": {},
   "source": [
    "### (Bonus/Optional) Third Model\n",
    "\n",
    "Create a third machine learning model and rerun steps (2) & (3) on this model. Which model has the best predictive capabilities? \n",
    "\n",
    "Create as many code-blocks as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit model\n",
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=len(y_resampled[y_resampled == 0]) / len(y_resampled[y_resampled == 1]),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train model\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "print(\"\\n XGBoost Results:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c37d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def get_metrics(y_true, y_pred, model_name):\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Precision\": precision_score(y_true, y_pred),\n",
    "        \"Recall\": recall_score(y_true, y_pred),\n",
    "        \"F1 Score\": f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "results = [\n",
    "    get_metrics(y_test, y_pred_rfc, \"Random Forest\"),\n",
    "    get_metrics(y_test, y_pred_lr, \"Logistic Regression\"),\n",
    "    get_metrics(y_test, y_pred_xgb, \"XGBoost\")\n",
    "]\n",
    "\n",
    "metrics_df = pd.DataFrame(results)\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
